<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bootstrap.min.css">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/app.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation</h1>
            <h2 class="subtitle is-3 publication-subtitle">CVPR 2025</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Sen Wang</a><sup>1</sup>,</span>
              <span class="author-block">
                Le Wang</a><sup>1†</sup>,</span>
              <span class="author-block">
                Sanping Zhou</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Jingyi Tian</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Jiayi Li</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Haowen Sun</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Wei Tang</a><sup>2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Xi’an Jiaotong University,</span>
              <span class="author-block"><sup>2</sup>University of Illinois at Chicago,</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2506.16201" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/SanMumumu/FlowRAM"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video> -->
        <img src="./static/images/teaser-1.png" class="interpolation-image" />
        <h2 class="subtitle has-text-centered">
           FlowRAM is a Mamba-based framework, where multimodal Mamba processes
          multi-view RGB images, geometric information, instructions, and robot proprioception.
        </h2>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-ketchup">
            <video poster="" id="ketchup" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chess_sim.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-plane">
            <video poster="" id="plane" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/insert_s.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fox">
            <video poster="" id="fox" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/nail.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toast">
            <video poster="" id="toast" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/plug.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-ruins">
            <video poster="" id="ruins" autoplay controls muted loop playsinline height="80%">
              <source src="./static/videos/usb.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
            Robotic manipulation in high-precision tasks is essential for numerous industrial and real-world applications where accuracy and speed are required.
              Yet current diffusion-based policy learning methods generally suffer from low computational efficiency due to the iterative denoising process during inference.
              Moreover, these methods do not fully explore the potential of generative models for enhancing information exploration in 3D environments.
              In response, we propose FlowRAM, a novel framework that leverages generative models to achieve region-aware perception, enabling efficient multimodal information processing.
              Specifically, we devise a Dynamic Radius Schedule, which allows adaptive perception, facilitating transitions from global scene comprehension to fine-grained geometric details.
              Furthermore, we integrate state space models to integrate multimodal information, while preserving linear computational complexity.
              In addition, we employ conditional flow matching to learn action poses by regressing deterministic vector fields, simplifying the learning process while maintaining performance.

            </p>
            <p>
              We verify the effectiveness of the FlowRAM in the RLBench, an established manipulation benchmark, and achieve state-of-the-art performance.
              The results demonstrate that FlowRAM achieves a remarkable improvement, particularly in high-precision tasks, where it outperforms previous methods by 12.0\% in average success rate.
              Additionally, FlowRAM is able to generate physically plausible actions for a variety of real-world tasks in less than 4 time steps, significantly increasing inference speed.
            </p>
          </div>
        </div>
      </div>

      <!--/ Paper video. -->
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Pipeline</h2>
      <img src="./static/images/pipeline-1.jpg" class="interpolation-image" />
      <p>
        FlowRAM is a Mamba-based framework, where multimodal Mamba processes multi-view RGB images, geometric information, instructions, and robot proprioception.
        In flow matching, noise-perturbed actions are transported to target actions guided by observations. During training,
        a dynamic radius schedule adjusts the perception radius over random discrete time steps,
        enabling the model to capture regions of varying sizes and adapt to diverse manipulation tasks by extracting comprehensive semantic and geometric features.

      </p>
    </div>
  </section>




  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Real World Deployment</h2>
      <p>
          We validate our approach on real-world robotic manipulation tasks using a 6-DoF UR5 arm equipped with a Robotiq gripper.
      </p>
      <br>
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;">Put Fruit in Bowl</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fruits.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;">Place Earphone on Block</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/earphone.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;">Take Skewer to tiny box</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pnp.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;">Setup Chess</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chess.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;"> Insert in Pen cap</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/insert.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="column">
          <div class="content">
            <h4 class="title is-size-5" style="text-align: center;">Setup Chess (Failed)</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chessF.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <!--/ Matting. -->


      <!-- Concurrent Work. -->
      <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              There's a lot of excellent work that was introduced around the same time as ours.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an
              idea similar to our windowed position encoding for coarse-to-fine optimization.
            </p>
            <p>
              <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
              both use deformation fields to model non-rigid scenes.
            </p>
            <p>
              Some works model videos with a NeRF by directly modulating the density, such as <a
                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                href="https://neural-3d-video.github.io/">DyNeRF</a>
            </p>
            <p>
              There are probably many more by the time you are reading this. Check out <a
                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
            </p>
          </div>
        </div>
      </div> -->
      <!--/ Concurrent Work. -->

    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>
      <img src="./static/images/main18.png" class="interpolation-image" />
      <p>
      <img src="./static/images/gnf.png" class="interpolation-image" />
      </p>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wang2025flowram,
  title={FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation},
  author={Wang, Sen and Wang, Le and Zhou, Sanping and Tian, Jingyi and Li, Jiayi and Sun, Haowen and Tang, Wei},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={12176--12186},
  year={2025}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/abs/2506.16201">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/SanMumumu/FlowRAM" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
              We thank the authors for sharing the template.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>